# WildNav with OmniGlue Integration ğŸ›¸ğŸ“

## Overview

This repository contains **WildNav** (GNSS-free UAV localization) enhanced with **OmniGlue** (CVPR 2024 feature matching). The integration improves localization accuracy and generalization to unseen environments.

### What's New?

âœ… **OmniGlue Matcher** - State-of-the-art feature matching with foundation model guidance
âœ… **Better Generalization** - 18.8% improvement on out-of-domain data
âœ… **Seamless Integration** - Drop-in replacement, keeps original pipeline
âœ… **Easy Switching** - Toggle between SuperGlue and OmniGlue
âœ… **Colab-Ready** - Optimized for Google Colab with persistent model storage
âœ… **Comprehensive Testing** - Full test suite with validation

---

## ğŸš€ Quick Start

### For Google Colab Users (Recommended)

See **[COLAB_QUICKSTART.md](COLAB_QUICKSTART.md)** - Get running in 10 minutes!

```python
# In Colab notebook:
!git clone <your-repo-url>
%cd wildnav
!python setup_models_colab.py
!pip install -q -r requirements_omniglue.txt
%cd src
!python test_integration.py  # Verify installation
!python wildnav.py           # Run localization
```

### For Local Users

```bash
cd wildnav
pip install -r requirements_omniglue.txt
bash setup_models.sh
cd src
python test_integration.py
python wildnav.py
```

---

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| **[COLAB_QUICKSTART.md](COLAB_QUICKSTART.md)** | 10-minute Colab tutorial |
| **[INTEGRATION.md](INTEGRATION.md)** | Complete integration guide |
| **[CLAUDE.md](../CLAUDE.md)** | Developer reference & migration plan |
| **[config_omniglue.yaml](config_omniglue.yaml)** | Tunable parameters |

---

## ğŸ“ Key Files

### New Integration Files
```
wildnav/
â”œâ”€â”€ requirements_omniglue.txt       â­ Unified dependencies
â”œâ”€â”€ config_omniglue.yaml            â­ Configuration
â”œâ”€â”€ setup_models_colab.py           â­ Model downloader (Colab)
â”œâ”€â”€ setup_models.sh                 â­ Model downloader (bash)
â”œâ”€â”€ INTEGRATION.md                  â­ Integration docs
â”œâ”€â”€ COLAB_QUICKSTART.md             â­ Quick start guide
â”œâ”€â”€ models/                         â­ Model weights (~375MB)
â”‚   â”œâ”€â”€ sp_v6/
â”‚   â”œâ”€â”€ dinov2_vitb14_pretrain.pth
â”‚   â””â”€â”€ og_export/
â””â”€â”€ src/
    â”œâ”€â”€ wildnav.py                  ğŸ”§ Modified (matcher selection)
    â”œâ”€â”€ omniglue_utils.py           â­ New wrapper module
    â”œâ”€â”€ test_integration.py         â­ Test suite
    â””â”€â”€ omniglue_lib/               â­ OmniGlue source
```

### Original WildNav Files
```
wildnav/
â”œâ”€â”€ README.md                       # Original documentation
â”œâ”€â”€ requirements.txt                # Original dependencies
â””â”€â”€ src/
    â”œâ”€â”€ superglue_utils.py          # Original matcher
    â”œâ”€â”€ build_map.py                # Satellite downloader
    â”œâ”€â”€ extract_image_meta_exif.py  # EXIF extractor
    â””â”€â”€ plot_data.py                # Results visualizer
```

---

## ğŸ¯ Usage

### Basic Localization

```bash
cd wildnav/src
python wildnav.py
```

**Input:**
- Drone images: `assets/query/*.jpg`
- Satellite maps: `assets/map/*.png`
- Metadata: `assets/query/photo_metadata.csv`, `assets/map/map.csv`

**Output:**
- Visualizations: `results/*_located.png`
- Coordinates: `results/calculated_coordinates.csv`

### Switch Between Matchers

Edit `src/wildnav.py` line 8:
```python
USE_OMNIGLUE = True   # OmniGlue (new)
USE_OMNIGLUE = False  # SuperGlue (original)
```

### Tune Parameters

Edit `config_omniglue.yaml`:
```yaml
omniglue:
  confidence_threshold: 0.02  # Adjust 0.01-0.05
  resize_max: 800             # Adjust 512-800
```

### Test Installation

```bash
cd src
python test_integration.py
```

Expected output: `7/7 tests passed`

---

## ğŸ”¬ How It Works

### Pipeline Comparison

**Original (SuperGlue):**
```
Query Image â†’ SuperPoint â†’ SuperGlue â†’ RANSAC â†’ Location
```

**New (OmniGlue):**
```
Query Image â†’ SuperPoint â”€â”€â”
               â†“           â”œâ†’ OmniGlue â†’ RANSAC â†’ Location
              DINOv2 â”€â”€â”€â”€â”€â”€â”˜
```

### Key Advantages

1. **Foundation Model Guidance** - DINOv2 provides semantic-rich features
2. **Better Generalization** - Works across seasons, weather, lighting
3. **Position-Guided Attention** - Disentangles spatial/appearance info
4. **Maintained Compatibility** - Same output format as original

---

## ğŸ“Š Expected Performance

### Baseline (SuperGlue)
- **Success Rate:** 56-62%
- **MAE:** 15.82-26.58m

### Target (OmniGlue)
- **Success Rate:** 65%+ (goal)
- **MAE:** <15m (goal)
- **Generalization:** +18.8% on out-of-domain data

### Computational Cost (GPU)
- **Model Load:** 3-5 seconds (once)
- **Per Image Pair:** 0.2-0.5 seconds
- **Full Dataset:** 5-10 minutes (100 images, 15 patches)

---

## ğŸ› ï¸ Configuration Options

### Matching Parameters

```yaml
# config_omniglue.yaml

# Confidence threshold (0.0 - 1.0)
confidence_threshold: 0.02

# Image resize (pixels)
resize_max: 800

# RANSAC threshold (pixels)
ransac.threshold: 5.0

# Selection strategy
selection.primary_criterion: "num_matches"  # or "confidence_sum"
```

### Performance Tuning

```yaml
# Use GPU
performance.use_gpu: true

# Early stopping (0.0 - 1.0)
performance.early_stop_confidence: 0.95

# Batch processing
performance.batch_size: 1
```

---

## ğŸ› Troubleshooting

### Quick Diagnostics

```bash
cd src
python test_integration.py
```

### Common Issues

| Issue | Solution |
|-------|----------|
| **Models not found** | Run `python setup_models_colab.py` |
| **TF/PyTorch conflict** | `pip install tensorflow>=2.12 torch>=2.0` |
| **CUDA OOM** | Reduce `resize_max` to 512 or 630 |
| **No matches** | Lower `confidence_threshold` to 0.01 |
| **Slow** | Verify GPU: `nvidia-smi` |

Full troubleshooting: See [INTEGRATION.md](INTEGRATION.md#troubleshooting)

---

## ğŸ“ˆ Validation Workflow

### 1. Test Integration
```bash
python test_integration.py
```

### 2. Run Localization
```bash
python wildnav.py
```

### 3. Analyze Results
```bash
python plot_data.py
```

### 4. Compare Matchers
```python
# A/B testing
USE_OMNIGLUE = True  â†’ Run â†’ Save results as omniglue_results.csv
USE_OMNIGLUE = False â†’ Run â†’ Save results as superglue_results.csv
# Compare MAE, success rate
```

---

## ğŸ”® Future Enhancements

- [ ] Batch processing for parallel satellite patch matching
- [ ] Adaptive confidence thresholding based on image quality
- [ ] Temporal smoothing with Kalman filter
- [ ] Fine-tuning OmniGlue on aerial-specific datasets
- [ ] Real-time optimization for onboard UAV processing
- [ ] Web interface for remote localization

---

## ğŸ“– References

### Papers
- **OmniGlue:** "Generalizable Feature Matching with Foundation Model Guidance" (CVPR 2024)
  [arXiv](https://arxiv.org/abs/2405.12979) | [GitHub](https://github.com/google-research/omniglue)

- **WildNav:** "Vision-Based GNSS-Free Localization for UAVs in the Wild" (IEEE ICMERR 2022)
  [DOI](https://doi.org/10.1109/ICMERR56497.2022.10097798) | [GitHub](https://github.com/TIERS/wildnav)

- **SuperGlue:** "Learning Feature Matching with Graph Neural Networks" (CVPR 2020)
  [GitHub](https://github.com/magicleap/SuperGluePretrainedNetwork)

- **DINOv2:** "Learning Robust Visual Features without Supervision" (2023)
  [GitHub](https://github.com/facebookresearch/dinov2)

### Resources
- [Original WildNav README](README.md)
- [Integration Details](INTEGRATION.md)
- [Colab Tutorial](COLAB_QUICKSTART.md)
- [Developer Guide](../CLAUDE.md)

---

## ğŸ¤ Contributing

### Testing New Configurations

1. Modify `config_omniglue.yaml`
2. Run `python wildnav.py`
3. Compare with baseline results
4. Share findings!

### Reporting Issues

Include in your report:
- Output of `python test_integration.py`
- Configuration used (`config_omniglue.yaml`)
- Sample images (if possible)
- Error messages/logs

---

## ğŸ“œ License

- **WildNav:** Original license applies
- **OmniGlue:** Apache 2.0 License
- **Integration Code:** Inherits from parent projects

---

## ğŸ“ Citation

If you use this integration in your research:

```bibtex
@inproceedings{jiang2024omniglue,
  title={OmniGlue: Generalizable Feature Matching with Foundation Model Guidance},
  author={Jiang, Hanwen and Karpur, Arjun and Cao, Bingyi and Huang, Qixing and Araujo, Andre},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{wildnav2022,
  title={Vision-Based GNSS-Free Localization for UAVs in the Wild},
  booktitle={IEEE International Conference on Mechatronics, Electronics and Robotics Research},
  year={2022}
}
```

---

## âœ¨ Acknowledgments

- **TIERS Lab** - Original WildNav implementation
- **Google Research** - OmniGlue implementation
- **Meta AI** - DINOv2 foundation model
- **Magic Leap** - SuperGlue baseline

---

## ğŸ“ Support

- **Integration Issues:** Open issue in this repository
- **WildNav Issues:** https://github.com/TIERS/wildnav/issues
- **OmniGlue Issues:** https://github.com/google-research/omniglue/issues

---

**Version:** 1.0
**Last Updated:** 2025-11-20
**Status:** âœ… Ready for Testing

---

Happy Localizing! ğŸ›¸ğŸ“
